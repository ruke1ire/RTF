# @package _global_
train:
  interval: epoch
scheduler:
  # _target_: torch.optim.lr_scheduler.CosineAnnealingLR
  _name_: cosine
  T_max: 100  # Max number of epochs steps for LR scheduler
  eta_min: 1e-6  # Min learning rate for cosine scheduler
